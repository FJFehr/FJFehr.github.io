---
layout: archive
title: "Updates"
permalink: /updates/
author_profile: true
redirect_from: 
  - /updates
---

## 2024


**[August 2024]**

Our paper [**Nonparametric Variational Regularisation of Pretrained Transformers**](https://arxiv.org/pdf/2312.00662.pdf) has been accepted to be presented at [COLM 2024](https://colmweb.org/)!

**[July 2024]**

Starting a research internship at Amazon, Berlin. I will be working in the space of retrieval augmented generation (RAG) and Large Language Models (LLMs) for code generation with [Prabhu Teja](https://prabhuteja12.github.io/) and [Giovanni Zappella](https://giovannizappella.github.io/)


**[April 2024]**

Reveiwing for the journal [**IEEE Transactions on Pattern Analysis and Machine Intelligence**](https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34)

**[March 2024]**

Presented a seminar to the [**Department of Statistical Sciences**](https://science.uct.ac.za/department-statistics) at the [**University of Cape Town**](https://uct.ac.za/). The talk was on the evolution of NLP, the attention mechanism and my PhD Research. See the [slides](https://FJFehr.github.io/files/UCT_Seminar_final.pdf).

**[January 2024]**

Reviewed for NAACL2024 as an emergency reviewer.

## 2023

**[December 2023]**

Our work on [**Learning to Abstract with Nonparametric Variational Information Bottleneck**](https://openreview.net/pdf?id=vU0KbvQ91x) will be presented at the [**Black Box NLP Workshop**](https://blackboxnlp.github.io/) EMNLP2023 in Singapore!

**[December 2023]**

Our paper [**Nonparametric Variational Regularisation of Pretrained Transformers**](https://arxiv.org/pdf/2312.00662.pdf) is on ArXiv.


**[October 2023]**

Our short paper [**Learning to Abstract with Nonparametric Variational Information Bottleneck**](https://openreview.net/pdf?id=vU0KbvQ91x) is accepted to findings of EMNLP 2023 in Singapore, ([Paper](https://openreview.net/pdf?id=vU0KbvQ91x)) ([Demo](https://huggingface.co/spaces/FJFehr/NVIB-Self-Attention-Demo)) ([Poster](https://FJFehr.github.io/files/NVIB_SA_poster.pdf)) ([Code](https://github.com/idiap/nvib_selfattention))


**[Autumn Semester 2023]**

Teaching for [**PhD: Deep Learning for Natural Language Processing**](https://edu.epfl.ch/coursebook/en/deep-learning-for-natural-language-processing-EE-608) at EPFL and [**Masters: Natural Language Processing**](https://unidistance.ch/en/mathematics-and-computer-science/master-in-artificial-intelligence/programme-of-the-master-in-artificial-intelligence) at UniDistance.

**[August 2023]**

Interviewed by the Bayes Newsletter of the South African Statistical Association (SASA) - [**The Journey from Undergraduate to PhD**](https://FJFehr.github.io/files/interview.pdf)

**[July 2023]**

Joined the company [**Defiant**](https://www.defiant.com/) for a week in Banff, Canada as an AI consultant.  


**[June 2023]**

Attending the [**Generative Modeling Summer School**](https://gemss.ai/) GeMSS 2023 in Copenhagen, Denmark.  


**[May 2023]**

Attending the 2023 ICLR conference in Kigali, Rwanda

**[April 2023]**

Our paper [**HyperMixer: An MLP-based Low Cost Alternative to Transformers**](https://arxiv.org/abs/2203.03691) is accepted to ACL 2023, ([Paper](https://arxiv.org/pdf/2203.03691.pdf)) ([Poster](https://FJFehr.github.io/files/Hypermixer_Poster.pdf)) ([Code](https://github.com/idiap/hypermixing))


**[January 2023]**

Our paper [A Variational AutoEncoder for Transformers with Nonparametric Variational Information Bottleneck](https://openreview.net/forum?id=6QkjC_cs03X) is accepted to ICLR 2023. ([Paper](https://openreview.net/forum?id=6QkjC_cs03X)) ([Poster](https://FJFehr.github.io/files/NVIB_Poster.pdf)) ([Code](https://github.com/idiap/nvib))

## 2022

**[July 2022]**   
Our paper [A Variational AutoEncoder for Transformers with Nonparametric Variational Information Bottleneck](https://arxiv.org/abs/2207.13529) is on Arxiv.

**[May 2022]**   
Attended the 2022 ACL Conference in Dublin, Ireland.

**[March 2022]**   
Our paper [HyperMixer: An MLP-based Green AI Alternative to Transformers](https://arxiv.org/abs/2203.03691) is on Arxiv.

**[Spring Semester 2022]**   
Passed the course [Human language technology: applications to information access](https://edu.epfl.ch/coursebook/en/human-language-technology-applications-to-information-access-EE-724?). This course allowed for fine-tuning skills in NLP and provided a more holistic picture of current research space.

**[February 2022]**   
Successfully passed my candidacy exam. I am officially a PhD candidate of the Electrical Engineering Department of EPFL.

## 2021

**[September 2021]**   
Participated in the [SciFilmIt Hackathon Geneva 2021](https://www.youtube.com/watch?v=Gm_JDGQxTdQ&ab_channel=SciFilmIt). This let me work with a diverse team to bring a probability concept through a visual medium for the public.


**[Autumn Semester 2021]**   
Passed the course [Scientific programming for Engineers](https://edu.epfl.ch/coursebook/en/scientific-programming-for-engineers-MATH-611#:~:text=Summary,complexity%2C%20optimization%20and%20program%20designs.). This course provided fundamentals in code development and practical applications in C++.

**[Autumn Semester 2021]**   
Passed the course [Deep Learning For Natural Language Processing](https://edu.epfl.ch/coursebook/en/deep-learning-for-natural-language-processing-EE-608). This course gave good grounding in NLP and allowed for a group project which will hopefully lead to a publication.

**[April 2021]**   
Virtually attended the 2021 EACL Conference in Kyiv, Ukraine.

**[February 2021]**
Joined the Natural Language Understanding group under the supervision of Dr. James Henderson at the Idiap Research Institute as a research assistant.

**[January 2021]**   
Completed my MSc in Statistics at the University of Cape Town. My MSc thesis: [Modelling non-linearity in 3D shapes: A comparative study of Gaussian process morphable models and variational autoencoders for 3D shape data](https://open.uct.ac.za/handle/11427/35725).
  
